{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Ijiff1YOFM-K"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import SnowballStemmer\n",
        "\n",
        "import tensorflow  as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xLesIsSmN5hA",
        "outputId": "9e696cfb-7ca7-4638-b0ba-a58e8fcdf163"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reading the data"
      ],
      "metadata": {
        "id": "eyPilnEzU9GU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/drive/MyDrive/Machine_Learning/NLP/Text Similarity/quora-questions/train.csv')\n"
      ],
      "metadata": {
        "id": "4sUz-ZAIHr6A"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D5qTKy4GPovj",
        "outputId": "70e85ae2-0c7f-44aa-d7e5-643f8c7918b4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(404290, 6)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(data['is_duplicate'].value_counts(normalize = True))\n",
        "print(data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OpqdcZYbIwT-",
        "outputId": "cbbbfe69-8d09-4ef8-ee2f-8038cdbcad76"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    0.630802\n",
            "1    0.369198\n",
            "Name: is_duplicate, dtype: float64\n",
            "(404290, 6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data[data['is_duplicate'] == 0].sample(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "dZfTvvy6Ixqz",
        "outputId": "212f857a-d90a-40cf-e283-86ea8de1a8cf"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            id    qid1    qid2  \\\n",
              "94690    94690   97582  158061   \n",
              "13412    13412   25759   25760   \n",
              "13159    13159   23832    5545   \n",
              "231198  231198   23989  238250   \n",
              "204375  204375  307250  307251   \n",
              "\n",
              "                                                question1  \\\n",
              "94690   What are the health benefits of cranberry-grap...   \n",
              "13412   How can I learn digital marketing step by step...   \n",
              "13159   How do you delete a picture from instagram on ...   \n",
              "231198  What is the difference between molecular mass,...   \n",
              "204375  How do I implement a PID Controllers for heate...   \n",
              "\n",
              "                                                question2  is_duplicate  \n",
              "94690   How do you determine the gluten in grape nuts?...             0  \n",
              "13412   What are good ways to learn to become the best...             0  \n",
              "13159             How do I delete a picture on Instagram?             0  \n",
              "231198  What is the difference between molecular mass ...             0  \n",
              "204375     Why is a P controller used for a flow process?             0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6fc3ec63-f776-40c7-95b0-643f7f3b5b32\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>qid1</th>\n",
              "      <th>qid2</th>\n",
              "      <th>question1</th>\n",
              "      <th>question2</th>\n",
              "      <th>is_duplicate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>94690</th>\n",
              "      <td>94690</td>\n",
              "      <td>97582</td>\n",
              "      <td>158061</td>\n",
              "      <td>What are the health benefits of cranberry-grap...</td>\n",
              "      <td>How do you determine the gluten in grape nuts?...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13412</th>\n",
              "      <td>13412</td>\n",
              "      <td>25759</td>\n",
              "      <td>25760</td>\n",
              "      <td>How can I learn digital marketing step by step...</td>\n",
              "      <td>What are good ways to learn to become the best...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13159</th>\n",
              "      <td>13159</td>\n",
              "      <td>23832</td>\n",
              "      <td>5545</td>\n",
              "      <td>How do you delete a picture from instagram on ...</td>\n",
              "      <td>How do I delete a picture on Instagram?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>231198</th>\n",
              "      <td>231198</td>\n",
              "      <td>23989</td>\n",
              "      <td>238250</td>\n",
              "      <td>What is the difference between molecular mass,...</td>\n",
              "      <td>What is the difference between molecular mass ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>204375</th>\n",
              "      <td>204375</td>\n",
              "      <td>307250</td>\n",
              "      <td>307251</td>\n",
              "      <td>How do I implement a PID Controllers for heate...</td>\n",
              "      <td>Why is a P controller used for a flow process?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6fc3ec63-f776-40c7-95b0-643f7f3b5b32')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6fc3ec63-f776-40c7-95b0-643f7f3b5b32 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6fc3ec63-f776-40c7-95b0-643f7f3b5b32');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7mEEc9kgN3Lx"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[data['is_duplicate'] == 1].sample(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "tMTJJ4yzJa5I",
        "outputId": "d91443a6-fe0d-44a9-ff48-f06313a656d1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            id    qid1    qid2  \\\n",
              "101014  101014   16472  101660   \n",
              "58235    58235   30182   28681   \n",
              "257474  257474  372797  372798   \n",
              "219458  219458  251578  195748   \n",
              "148219  148219  233754  233755   \n",
              "\n",
              "                                                question1  \\\n",
              "101014  What are the creepiest paranormal experience y...   \n",
              "58235   How is borderline personality disorder (BPD) t...   \n",
              "257474  Will my Q&A disappear if I delete my Quora acc...   \n",
              "219458  What are some of the best hangout places in Pune?   \n",
              "148219  Are there any good software companies in Singa...   \n",
              "\n",
              "                                                question2  is_duplicate  \n",
              "101014  What is the scariest paranormal encounter you'...             1  \n",
              "58235            What is borderline personality disorder?             1  \n",
              "257474  What happens to the questions and answers you ...             1  \n",
              "219458  What are some places to spend the weekend near...             1  \n",
              "148219    Which are good software companies in Singapore?             1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3a71eed6-6831-4de4-b9de-861104d9841c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>qid1</th>\n",
              "      <th>qid2</th>\n",
              "      <th>question1</th>\n",
              "      <th>question2</th>\n",
              "      <th>is_duplicate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>101014</th>\n",
              "      <td>101014</td>\n",
              "      <td>16472</td>\n",
              "      <td>101660</td>\n",
              "      <td>What are the creepiest paranormal experience y...</td>\n",
              "      <td>What is the scariest paranormal encounter you'...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58235</th>\n",
              "      <td>58235</td>\n",
              "      <td>30182</td>\n",
              "      <td>28681</td>\n",
              "      <td>How is borderline personality disorder (BPD) t...</td>\n",
              "      <td>What is borderline personality disorder?</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>257474</th>\n",
              "      <td>257474</td>\n",
              "      <td>372797</td>\n",
              "      <td>372798</td>\n",
              "      <td>Will my Q&amp;A disappear if I delete my Quora acc...</td>\n",
              "      <td>What happens to the questions and answers you ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>219458</th>\n",
              "      <td>219458</td>\n",
              "      <td>251578</td>\n",
              "      <td>195748</td>\n",
              "      <td>What are some of the best hangout places in Pune?</td>\n",
              "      <td>What are some places to spend the weekend near...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148219</th>\n",
              "      <td>148219</td>\n",
              "      <td>233754</td>\n",
              "      <td>233755</td>\n",
              "      <td>Are there any good software companies in Singa...</td>\n",
              "      <td>Which are good software companies in Singapore?</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3a71eed6-6831-4de4-b9de-861104d9841c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3a71eed6-6831-4de4-b9de-861104d9841c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3a71eed6-6831-4de4-b9de-861104d9841c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need to clean our questions text before we use them for training any model. As the questions are repeated in our training set, it makes sense to make a dataframe with unique questions, clean them. We can then use our cleaned questions to train the model while spending less time cleaning the questions."
      ],
      "metadata": {
        "id": "FMjkgr7cVAWi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "questions = pd.concat([data[['qid1','question1']].drop_duplicates().rename({'qid1':'qid','question1':'question'},axis = 1),data[['qid2','question2']].drop_duplicates().rename({'qid2':'qid','question2':'question'},axis = 1) ]).sort_values('qid')\n",
        "questions = questions.drop_duplicates()"
      ],
      "metadata": {
        "id": "uEFy9vKCLt4K"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = data[['id','qid1','qid2','is_duplicate']].copy()"
      ],
      "metadata": {
        "id": "9efz0XHwSG54"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "questions.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "n9BlUpk6MoaV",
        "outputId": "86bf5a29-9b84-4bc4-f18d-2cbec8ace2cf"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   qid                                           question\n",
              "0    1  What is the step by step guide to invest in sh...\n",
              "0    2  What is the step by step guide to invest in sh...\n",
              "1    3  What is the story of Kohinoor (Koh-i-Noor) Dia...\n",
              "1    4  What would happen if the Indian government sto...\n",
              "2    5  How can I increase the speed of my internet co..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c2d81b12-27bb-4fc4-8747-427f94ec4846\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>qid</th>\n",
              "      <th>question</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>What is the step by step guide to invest in sh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>What is the step by step guide to invest in sh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>What would happen if the Indian government sto...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>How can I increase the speed of my internet co...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c2d81b12-27bb-4fc4-8747-427f94ec4846')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c2d81b12-27bb-4fc4-8747-427f94ec4846 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c2d81b12-27bb-4fc4-8747-427f94ec4846');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DKem2_R1Vo7S"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cleaning Text"
      ],
      "metadata": {
        "id": "B3x56OnvVqBz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "stop_words = set(stopwords.words('english')) - set(['not','what','why','how','who','whom','which'])\n",
        "stemmer = SnowballStemmer('english')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "huUl5XJrK54h",
        "outputId": "f2c357bc-fa12-4a93-e36f-733b56e3035b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_html_tags(text):\n",
        "  text = re.sub(r'<.*?>','',text)\n",
        "  return text\n",
        "\n",
        "def remove_special_characters(text):\n",
        "  text = re.sub(r\"[^A-Za-z0-9^,!.\\/'+-=]\", \" \", text)\n",
        "  text = re.sub(r\"what's\", \"what is \", text)\n",
        "  text = re.sub(r\"\\'s\", \" \", text)\n",
        "  text = re.sub(r\"\\'ve\", \" have \", text)\n",
        "  text = re.sub(r\"can't\", \"cannot \", text)\n",
        "  text = re.sub(r\"n't\", \" not \", text)\n",
        "  text = re.sub(r\"i'm\", \"i am \", text)\n",
        "  text = re.sub(r\"\\'re\", \" are \", text)\n",
        "  text = re.sub(r\"\\'d\", \" would \", text)\n",
        "  text = re.sub(r\"\\'ll\", \" will \", text)\n",
        "  text = re.sub(r\",\", \" \", text)\n",
        "  text = re.sub(r\"\\.\", \" \", text)\n",
        "  text = re.sub(r\"!\", \" ! \", text)\n",
        "  text = re.sub(r\"\\/\", \" \", text)\n",
        "  text = re.sub(r\"\\^\", \" ^ \", text)\n",
        "  text = re.sub(r\"\\+\", \" + \", text)\n",
        "  text = re.sub(r\"\\-\", \" - \", text)\n",
        "  text = re.sub(r\"\\=\", \" = \", text)\n",
        "  text = re.sub(r\"'\", \" \", text)\n",
        "  text = re.sub(r\":\", \" : \", text)\n",
        "  text = re.sub(r\"(\\d+)(k)\", r\"\\g<1>000\", text)\n",
        "  text = re.sub(r\" e g \", \" eg \", text)\n",
        "  text = re.sub(r\" b g \", \" bg \", text)\n",
        "  text = re.sub(r\" u s \", \" american \", text)\n",
        "  text = re.sub(r\" 9 11 \", \"911\", text)\n",
        "  text = re.sub(r\"e - mail\", \"email\", text)\n",
        "  text = re.sub(r\"j k\", \"jk\", text)\n",
        "  text = re.sub(r\"\\s{2,}\", \" \", text)\n",
        "  return text\n",
        "\n",
        "def lower_the_text(text):\n",
        "  return text.lower()\n",
        "\n",
        "def tokenize_text(text):\n",
        "  return word_tokenize(text)\n",
        "\n",
        "def remove_stopwords(tokenized_text):\n",
        "  return [word for word in tokenized_text if word not in stop_words]\n",
        "\n",
        "def stem_text(tokenized_text):\n",
        "  return [stemmer.stem(word) for word in tokenized_text]\n",
        "\n",
        "\n",
        "def clean_ques(text,rem_stopwords_flag = False, stem_text_flag = False,return_string = True):\n",
        "  text = remove_html_tags(text)\n",
        "  text = remove_special_characters(text)\n",
        "  text = lower_the_text(text)\n",
        "  tokenized_text = tokenize_text(text)\n",
        "\n",
        "  if rem_stopwords_flag:\n",
        "    tokenized_text = remove_stopwords(tokenized_text)\n",
        "  if stem_text_flag:\n",
        "    tokenized_text = stem_text(tokenized_text)\n",
        "  \n",
        "  if(return_string):\n",
        "    return \" \".join(tokenized_text)\n",
        "\n",
        "  return tokenized_text\n",
        "  \n",
        "  "
      ],
      "metadata": {
        "id": "RW_sxphnK1P5"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cleaning and saving our cleaned questions dataframe to be reused each time we run the program"
      ],
      "metadata": {
        "id": "td54-1vVWQVI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %%time\n",
        "# questions['cleaned_question'] = questions['question'].apply(lambda x: clean_ques(str(x),rem_stopwords_flag = False, stem_text_flag = True,return_string = True) )"
      ],
      "metadata": {
        "id": "4xCmru6DNcWB"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# questions.to_csv('/content/drive/MyDrive/Machine_Learning/NLP/Text Similarity/quora-questions/train_cleaned_questions.csv')\n"
      ],
      "metadata": {
        "id": "bUJjciUDLUTN"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JwAtJnp8WUer"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "reading saved cleaned questions"
      ],
      "metadata": {
        "id": "Wae0yiTbWU7u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "questions = pd.read_csv('/content/drive/MyDrive/Machine_Learning/NLP/Text Similarity/quora-questions/train_cleaned_questions.csv')\n",
        "questions['cleaned_question'] = questions['cleaned_question'].map(str)\n",
        "questions = questions[['qid','cleaned_question']].copy()"
      ],
      "metadata": {
        "id": "neL4UwL-lkyz"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "questions['cleaned_question'].apply(lambda x : len((x).split())).describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HnHToskhY96L",
        "outputId": "62d8f6bb-8375-4a3c-ce80-b69c1ef705d8"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    537933.000000\n",
              "mean         12.919239\n",
              "std           6.889712\n",
              "min           1.000000\n",
              "25%           9.000000\n",
              "50%          11.000000\n",
              "75%          15.000000\n",
              "max         272.000000\n",
              "Name: cleaned_question, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "questions['cleaned_question'].apply(lambda x : len(x.split())).quantile([0.90,0.95,0.99,0.995,0.999])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "poUGq_gLZGUe",
        "outputId": "b87fbf3b-24b6-4a1f-a720-0470826d4bab"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.900    22.0\n",
              "0.950    27.0\n",
              "0.990    37.0\n",
              "0.995    43.0\n",
              "0.999    61.0\n",
              "Name: cleaned_question, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Most of the cleaned questions have lengths <= 64 words. We can use this upper bound to efficiently build our model. It doesn't make sense to build a model that can handle 256 words in questions, as it is not memory efficient."
      ],
      "metadata": {
        "id": "vf9kjAmyWr52"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6H7LhZuUXIOp"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train-Validation split"
      ],
      "metadata": {
        "id": "1nC-ksRLXKXa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics import accuracy_score\n"
      ],
      "metadata": {
        "id": "p5WzxKGiKUdJ"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_val = train_test_split(data,test_size=0.2,random_state=99)\n",
        "\n"
      ],
      "metadata": {
        "id": "g9jzBGPyJe4q"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F22qX-kVXmHe"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "X_train and X_valid only contains questions ids. We need to map back the questions text to the data frames for training."
      ],
      "metadata": {
        "id": "M7lfmJqSXn1C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.merge(questions[['qid','cleaned_question']],left_on = 'qid1',right_on = 'qid', how = 'left').rename({'cleaned_question':'question1'},axis = 1)\n",
        "X_train = X_train.merge(questions[['qid','cleaned_question']],left_on = 'qid2',right_on = 'qid', how = 'left').rename({'cleaned_question':'question2'},axis = 1)\n",
        "\n",
        "X_val = X_val.merge(questions[['qid','cleaned_question']],left_on = 'qid1',right_on = 'qid', how = 'left').rename({'cleaned_question':'question1'},axis = 1).drop('qid',axis = 1)\n",
        "X_val = X_val.merge(questions[['qid','cleaned_question']],left_on = 'qid2',right_on = 'qid', how = 'left').rename({'cleaned_question':'question2'},axis = 1).drop('qid',axis = 1)\n",
        "\n"
      ],
      "metadata": {
        "id": "1xCOvl4PTVvH"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train['question1'] = X_train['question1'].map(str)\n",
        "X_train['question2'] = X_train['question2'].map(str)\n",
        "\n",
        "X_val['question1'] = X_val['question1'].map(str)\n",
        "X_val['question2'] = X_val['question2'].map(str)\n"
      ],
      "metadata": {
        "id": "__xZ4ohzl7rC"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JXan1_h_YMGc"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building Tensorflow Model"
      ],
      "metadata": {
        "id": "Z5H8LdGvYQHW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "VOCAB_SIZE = 8000\n",
        "BATCH_SIZE = 2048\n",
        "LEARNING_RATE = 5e-3\n",
        "\n",
        "vocab_size = VOCAB_SIZE\n",
        "batch_size = BATCH_SIZE\n",
        "learning_rate = LEARNING_RATE"
      ],
      "metadata": {
        "id": "xFiJWrzFbXUV"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Tokenizer and Padding\n",
        "\n"
      ],
      "metadata": {
        "id": "6k8M5uE3Y7UB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words = vocab_size,oov_token=1)\n"
      ],
      "metadata": {
        "id": "PpBlhKTfS0sd"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building and saving tokenizer for repeated use.\n",
        "\n"
      ],
      "metadata": {
        "id": "L3xHq9vjZG82"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenizer.fit_on_texts(np.concatenate([X_train['question1'].values,X_train['question2'].values]))\n",
        "\n",
        "# # saving\n",
        "# with open('/content/drive/MyDrive/Machine_Learning/NLP/Text Similarity/quora-questions/tokenizer.pickle', 'wb') as handle:\n",
        "#     pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "\n",
        "# loading\n",
        "with open('/content/drive/MyDrive/Machine_Learning/NLP/Text Similarity/quora-questions/tokenizer.pickle', 'rb') as handle:\n",
        "    tokenizer = pickle.load(handle)"
      ],
      "metadata": {
        "id": "E4LvaXfS2Peg"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pad_encoded_texts(encoded_texts,max_length = 64):\n",
        "  padded_encoded_texts = []\n",
        "  for encoded_text in encoded_texts:\n",
        "    encoded_text = encoded_text[:max_length]\n",
        "    encoded_text = encoded_text + [0]*(max_length - len(encoded_text))\n",
        "    padded_encoded_texts.append(encoded_text)\n",
        "  \n",
        "  return np.array(padded_encoded_texts)"
      ],
      "metadata": {
        "id": "txgXa8njVAQk"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Data generators for training"
      ],
      "metadata": {
        "id": "cqE0TI04aV5a"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def get_encoded_ques_pair_generator_function(questions_list1,questions_list2,y_list = None,shuffle = False,clean_ques_flag = True):\n",
        "  def get_encoded_ques_pair_generator(questions_list1 = questions_list1,question_list2 = questions_list1,shuffle = shuffle,clean_ques_flag = clean_ques_flag):\n",
        "    n_ques = len(questions_list1)\n",
        "    index_list = [i for i in range(n_ques)]\n",
        "    if(shuffle == True):\n",
        "      random.shuffle(index_list)\n",
        "    i = -1\n",
        "    while True:\n",
        "      i = i + 1\n",
        "      if(i == n_ques):\n",
        "        i = 0\n",
        "        if(shuffle == True):\n",
        "          random.shuffle(index_list)\n",
        "      \n",
        "      # print(index_list)\n",
        "      q1 = questions_list1[index_list[i]]\n",
        "      q2 = questions_list2[index_list[i]]\n",
        "      if(y_list is not None):\n",
        "        y = y_list[index_list[i]]\n",
        "      if(clean_ques_flag):\n",
        "        q1 = clean_ques(q1)\n",
        "        q2 = clean_ques(q2)\n",
        "\n",
        "      if(y_list is None):\n",
        "        yield pad_encoded_texts(tokenizer.texts_to_sequences([q1]))[0],pad_encoded_texts(tokenizer.texts_to_sequences([q2]))[0]\n",
        "      else:\n",
        "        yield pad_encoded_texts(tokenizer.texts_to_sequences([q1]))[0],pad_encoded_texts(tokenizer.texts_to_sequences([q2]))[0],y\n",
        "\n",
        "  return get_encoded_ques_pair_generator\n"
      ],
      "metadata": {
        "id": "UlQdRcng2z4_"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator = get_encoded_ques_pair_generator_function(X_train['question1'].to_list(),X_train['question2'].to_list(),X_train['is_duplicate'].to_list(),shuffle = True,clean_ques_flag = False)\n",
        "val_generator = get_encoded_ques_pair_generator_function(X_val['question1'].to_list(),X_val['question2'].to_list(),X_val['is_duplicate'].to_list(),shuffle = False,clean_ques_flag = False)\n"
      ],
      "metadata": {
        "id": "93f8KQnvL4hM"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e2rkou7sVU-m"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating TF datasets for training"
      ],
      "metadata": {
        "id": "7xucXLUibDyq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = tf.data.Dataset.from_generator(train_generator,output_signature = (tf.TensorSpec(shape = (64,), dtype = tf.int32),tf.TensorSpec(shape = (64,), dtype = tf.int32),tf.TensorSpec(shape=(), dtype=tf.int32)))\n",
        "train_dataset = train_dataset.batch(batch_size)\n",
        "train_dataset = train_dataset.map(lambda q1,q2,y: ((q1,q2),y))\n",
        "train_dataset = train_dataset.prefetch(1)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wLqEk2NsbTrB"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_dataset = tf.data.Dataset.from_generator(val_generator,output_signature = (tf.TensorSpec(shape = (64,), dtype = tf.int32),tf.TensorSpec(shape = (64,), dtype = tf.int32),tf.TensorSpec(shape=(), dtype=tf.int32)))\n",
        "val_dataset = val_dataset.batch(batch_size)\n",
        "val_dataset = val_dataset.map(lambda q1,q2,y: ((q1,q2),y))\n",
        "val_dataset = val_dataset.prefetch(1)\n"
      ],
      "metadata": {
        "id": "zMd_QZ_8kG97"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QBn_G9ghpJ9a"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Building Siamese model architecture"
      ],
      "metadata": {
        "id": "IFcD-b1PbnLL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_siamese_network(vocab_size = vocab_size,d_model = 256,batch_size = 64,max_length = 64): \n",
        "\n",
        "  def build_tf_lstm_model():\n",
        "    encoded_question = layers.Input(batch_shape = (batch_size,max_length),name = 'input_encoded_question')\n",
        "    embeddings = layers.Embedding(vocab_size,d_model,input_length=max_length,name = 'embedding_layer')(encoded_question)\n",
        "    layer_1 =  layers.LSTM(d_model,return_sequences=True,stateful  = True,name = 'lstm_1')(embeddings)\n",
        "    layer_2 =  layers.LSTM(d_model,return_sequences=True,stateful  = True,name = 'lstm_2')(layer_1)\n",
        "    flat_layer_2 = layers.Flatten(name = 'flatten_lstm_2')(layer_2)\n",
        "    hidden_1 = layers.Dense(d_model,name = 'hidden_1')(flat_layer_2)\n",
        "    hidden_1 = layers.LayerNormalization()(hidden_1)\n",
        "    lstm_model  = Model(inputs = [encoded_question],outputs = [hidden_1])\n",
        "\n",
        "    return lstm_model\n",
        "\n",
        "\n",
        "  \n",
        "  encoded_question1 = layers.Input(batch_shape = (batch_size,max_length),name = 'input_encoded_question1')\n",
        "  encoded_question2 = layers.Input(batch_shape = (batch_size,max_length),name = 'input_encoded_question2')\n",
        "  \n",
        "  lstm_model = build_tf_lstm_model()\n",
        "  \n",
        "  embedded_questions1 = lstm_model(encoded_question1)\n",
        "  embedded_questions2 = lstm_model(encoded_question2)\n",
        "\n",
        "  similarity = layers.Dot(axes=(1, 1))([embedded_questions1, embedded_questions2])\n",
        "\n",
        "  output = layers.Dense(1, activation=\"sigmoid\")(similarity)\n",
        "\n",
        "  model  = Model(inputs = [encoded_question1,encoded_question2],outputs = [output])\n",
        "  \n",
        "  return model"
      ],
      "metadata": {
        "id": "oHvt2vGjmoUq"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KDudQUPoddbn"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training"
      ],
      "metadata": {
        "id": "Lyu9x3Nlddz6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = BATCH_SIZE\n",
        "learning_rate = LEARNING_RATE\n",
        "\n",
        "\n",
        "siamese_model = build_siamese_network(batch_size = batch_size)\n",
        "\n",
        "siamese_model.compile(loss  =  \"binary_crossentropy\", \n",
        "                optimizer = Adam(learning_rate  = learning_rate),\n",
        "                metrics = [tf.keras.metrics.BinaryAccuracy()])\n",
        "\n",
        "early_stopping = EarlyStopping(min_delta = 0.01,patience = 3,restore_best_weights=True)\n",
        "\n",
        "history = siamese_model.fit(train_dataset,\n",
        "                            batch_size = batch_size,\n",
        "                            steps_per_epoch = X_train.shape[0]//batch_size + 1,\n",
        "                            epochs = 20,\n",
        "                            validation_data=val_dataset,\n",
        "                            validation_steps = X_val.shape[0]//batch_size + 1,\n",
        "                            callbacks = [early_stopping])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-Skr3WEOacL",
        "outputId": "d0d779fd-4bd0-4e6f-82f0-e145e09acf47"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "158/158 [==============================] - 149s 909ms/step - loss: 53.0680 - binary_accuracy: 0.3695 - val_loss: 1.7320 - val_binary_accuracy: 0.3685\n",
            "Epoch 2/20\n",
            "158/158 [==============================] - 141s 891ms/step - loss: 0.7459 - binary_accuracy: 0.5598 - val_loss: 0.6584 - val_binary_accuracy: 0.6315\n",
            "Epoch 3/20\n",
            "158/158 [==============================] - 116s 736ms/step - loss: 0.6587 - binary_accuracy: 0.6306 - val_loss: 0.6582 - val_binary_accuracy: 0.6315\n",
            "Epoch 4/20\n",
            "158/158 [==============================] - 115s 728ms/step - loss: 0.6586 - binary_accuracy: 0.6307 - val_loss: 0.6581 - val_binary_accuracy: 0.6315\n",
            "Epoch 5/20\n",
            "158/158 [==============================] - 114s 721ms/step - loss: 0.6586 - binary_accuracy: 0.6307 - val_loss: 0.6582 - val_binary_accuracy: 0.6315\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "siamese_model.save('/content/drive/MyDrive/Machine_Learning/NLP/Text Similarity/quora-questions/siamese_baseline_0.h5')"
      ],
      "metadata": {
        "id": "hv99YA0GVYFh"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Log-loss on Kaggle test set:- Private: 0.56847 Public: 0.56748"
      ],
      "metadata": {
        "id": "txyWLBkqlXT-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Further improvements could be brought by:-\n",
        "1.   Using euclidean distance for simialarity instead of cosine similarity\n",
        "2.   Feature engineering like number of common words, characters in question pairs, etc.\n",
        "3.   Don't stem the words\n",
        "4.   Use glove embeddings instead of training new embeddings\n",
        "5.   Experiment with the d_model\n",
        "6.   Using BERT models or more complex models\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4JwMy61yhyxY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Replacing dot product with euclidean distance for similarity"
      ],
      "metadata": {
        "id": "gRDMX6HClrF-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow.keras.backend as K\n",
        "def build_siamese_network_euclidean_similarity(vocab_size = vocab_size,d_model = 256,batch_size = 64,max_length = 64): \n",
        "  def build_tf_lstm_model():\n",
        "    encoded_question = layers.Input(batch_shape = (batch_size,max_length),name = 'input_encoded_question')\n",
        "    embeddings = layers.Embedding(vocab_size,d_model,input_length=max_length,name = 'embedding_layer')(encoded_question)\n",
        "    layer_1 =  layers.LSTM(d_model,return_sequences=True,stateful  = True,name = 'lstm_1')(embeddings)\n",
        "    layer_2 =  layers.LSTM(d_model,return_sequences=True,stateful  = True,name = 'lstm_2')(layer_1)\n",
        "    flat_layer_2 = layers.Flatten(name = 'flatten_lstm_2')(layer_2)\n",
        "    hidden_1 = layers.Dense(d_model,name = 'hidden_1')(flat_layer_2)\n",
        "    hidden_1 = layers.LayerNormalization()(hidden_1)\n",
        "    lstm_model  = Model(inputs = [encoded_question],outputs = [hidden_1])\n",
        "\n",
        "    return lstm_model\n",
        "\n",
        "  def euclidean_distance(vectors):\n",
        "    (featsA, featsB) = vectors\n",
        "    sumSquared = K.sum(K.square(featsA - featsB), axis=1,\n",
        "      keepdims=True)\n",
        "    return K.sqrt(K.maximum(sumSquared, K.epsilon()))\n",
        "\n",
        "  \n",
        "  encoded_question1 = layers.Input(batch_shape = (batch_size,max_length),name = 'input_encoded_question1')\n",
        "  encoded_question2 = layers.Input(batch_shape = (batch_size,max_length),name = 'input_encoded_question2')\n",
        "  \n",
        "  lstm_model = build_tf_lstm_model()\n",
        "  \n",
        "  embedded_questions1 = lstm_model(encoded_question1)\n",
        "  embedded_questions2 = lstm_model(encoded_question2)\n",
        "\n",
        "  similarity = layers.Lambda(euclidean_distance)([embedded_questions1, embedded_questions2])\n",
        "\n",
        "  output = layers.Dense(1, activation=\"sigmoid\")(similarity)\n",
        "\n",
        "  model  = Model(inputs = [encoded_question1,encoded_question2],outputs = [output])\n",
        "  \n",
        "  return model"
      ],
      "metadata": {
        "id": "YDQuJPOyhxLI"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = BATCH_SIZE\n",
        "siamese_model = build_siamese_network_euclidean_similarity(batch_size = batch_size)\n",
        "\n",
        "siamese_model.compile(loss  =  \"binary_crossentropy\", \n",
        "                optimizer = Adam(learning_rate  = learning_rate),\n",
        "                metrics = [tf.keras.metrics.BinaryAccuracy()])\n",
        "\n",
        "early_stopping = EarlyStopping(min_delta = 0.01,patience = 3,restore_best_weights=True)\n",
        "\n",
        "history = siamese_model.fit(train_dataset,\n",
        "                            batch_size = batch_size,\n",
        "                            steps_per_epoch = X_train.shape[0]//batch_size + 1,\n",
        "                            epochs = 20,\n",
        "                            validation_data=val_dataset,\n",
        "                            validation_steps = X_val.shape[0]//batch_size + 1,\n",
        "                            callbacks = [early_stopping])\n"
      ],
      "metadata": {
        "id": "rJVoAgmUliwV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2eed7493-e72c-47a5-81d6-600cbb248abe"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "158/158 [==============================] - 122s 737ms/step - loss: 0.5815 - binary_accuracy: 0.6879 - val_loss: 0.5310 - val_binary_accuracy: 0.7417\n",
            "Epoch 2/20\n",
            "158/158 [==============================] - 115s 729ms/step - loss: 0.5123 - binary_accuracy: 0.7483 - val_loss: 0.5144 - val_binary_accuracy: 0.7494\n",
            "Epoch 3/20\n",
            "158/158 [==============================] - 115s 728ms/step - loss: 0.4801 - binary_accuracy: 0.7683 - val_loss: 0.4808 - val_binary_accuracy: 0.7702\n",
            "Epoch 4/20\n",
            "158/158 [==============================] - 115s 732ms/step - loss: 0.4496 - binary_accuracy: 0.7876 - val_loss: 0.4857 - val_binary_accuracy: 0.7804\n",
            "Epoch 5/20\n",
            "158/158 [==============================] - 115s 731ms/step - loss: 0.4233 - binary_accuracy: 0.8027 - val_loss: 0.4607 - val_binary_accuracy: 0.7858\n",
            "Epoch 6/20\n",
            "158/158 [==============================] - 114s 723ms/step - loss: 0.4029 - binary_accuracy: 0.8140 - val_loss: 0.4434 - val_binary_accuracy: 0.7964\n",
            "Epoch 7/20\n",
            "158/158 [==============================] - 114s 725ms/step - loss: 0.3809 - binary_accuracy: 0.8257 - val_loss: 0.4435 - val_binary_accuracy: 0.8029\n",
            "Epoch 8/20\n",
            "158/158 [==============================] - 114s 725ms/step - loss: 0.3589 - binary_accuracy: 0.8387 - val_loss: 0.4422 - val_binary_accuracy: 0.8051\n",
            "Epoch 9/20\n",
            "158/158 [==============================] - 114s 724ms/step - loss: 0.3376 - binary_accuracy: 0.8511 - val_loss: 0.4345 - val_binary_accuracy: 0.8117\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "siamese_model.save('/content/drive/MyDrive/Machine_Learning/NLP/Text Similarity/quora-questions/siamese_baseline_1.h5')"
      ],
      "metadata": {
        "id": "9pb9trHHFUWw"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model could be trained more as we can still see model is improving with each interation. But we are only experimenting for now and we learnt that using euclidean distance for similarity gives better result."
      ],
      "metadata": {
        "id": "JKr2JzudXt0U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Log-loss on Kaggle test set:- Private: 0.47721 Public: 0.47593"
      ],
      "metadata": {
        "id": "ZKPc61NZgV3Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prediction on test data"
      ],
      "metadata": {
        "id": "wfnrQUGHhrIk"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cmWLhjljmSj9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Predicting using model with dot product"
      ],
      "metadata": {
        "id": "F0Tsk41DmT5h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 1024\n",
        "siamese_model = build_siamese_network(batch_size = batch_size)"
      ],
      "metadata": {
        "id": "DwpqhHF0eXMa"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "siamese_model.load_weights('/content/drive/MyDrive/Machine_Learning/NLP/Text Similarity/quora-questions/siamese_baseline_0.h5')"
      ],
      "metadata": {
        "id": "apjdPYPJeXMc"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = pd.read_csv('/content/drive/MyDrive/Machine_Learning/NLP/Text Similarity/quora-questions/test.csv')\n",
        "test_data = test_data[test_data['test_id']!='life in dublin?\"'].copy()\n",
        "test_data['test_id'] = test_data['test_id'].map(int)\n",
        "test_data = test_data.drop_duplicates()\n",
        "test_generator = get_encoded_ques_pair_generator_function(test_data['question1'].map(str).to_list(),test_data['question2'].map(str).to_list(),None,shuffle = False,clean_ques_flag = True)\n",
        "test_dataset = tf.data.Dataset.from_generator(test_generator,output_signature = (tf.TensorSpec(shape = (64,), dtype = tf.int32),tf.TensorSpec(shape = (64,), dtype = tf.int32)))\n",
        "test_dataset = test_dataset.batch(batch_size)\n",
        "test_dataset = test_dataset.map(lambda q1,q2: ((q1,q2),1))\n",
        "test_dataset = test_dataset.prefetch(2)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "050f7c2e-182e-485c-b5c3-196d60c88e50",
        "id": "O7l45tFveXMd"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:3326: DtypeWarning: Columns (0) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_predict = siamese_model.predict(test_dataset,steps=test_data.shape[0]//batch_size + 1,verbose = 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27e8f789-b4b6-466e-efc5-4d0a96ab5dee",
        "id": "vMyVe6-KeXMd"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4582/4582 [==============================] - 1452s 317ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data['is_duplicate'] = y_test_predict[:test_data.shape[0]]"
      ],
      "metadata": {
        "id": "ZsjgPYA4eXMd"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission = test_data[['test_id','is_duplicate']].copy()\n",
        "submission.to_csv('/content/drive/MyDrive/Machine_Learning/NLP/Text Similarity/quora-questions/submission_baseline_0.csv',index = False)\n"
      ],
      "metadata": {
        "id": "cEvXnkz9eXMd"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "n_hItpx0md7K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Predicting using model with euclidean distance"
      ],
      "metadata": {
        "id": "iyA0A22Ime4p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 1024\n",
        "siamese_model = build_siamese_network_euclidean_similarity(batch_size = batch_size)"
      ],
      "metadata": {
        "id": "u2oyTYKmyN0V"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "siamese_model.load_weights('/content/drive/MyDrive/Machine_Learning/NLP/Text Similarity/quora-questions/siamese_baseline_1.h5')"
      ],
      "metadata": {
        "id": "Ci6V9G6Wy0bK"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mnui9FgEcanQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = pd.read_csv('/content/drive/MyDrive/Machine_Learning/NLP/Text Similarity/quora-questions/test.csv')\n",
        "test_data = test_data[test_data['test_id']!='life in dublin?\"'].copy()\n",
        "test_data['test_id'] = test_data['test_id'].map(int)\n",
        "test_data = test_data.drop_duplicates()\n",
        "test_generator = get_encoded_ques_pair_generator_function(test_data['question1'].map(str).to_list(),test_data['question2'].map(str).to_list(),None,shuffle = False,clean_ques_flag = True)\n",
        "test_dataset = tf.data.Dataset.from_generator(test_generator,output_signature = (tf.TensorSpec(shape = (64,), dtype = tf.int32),tf.TensorSpec(shape = (64,), dtype = tf.int32)))\n",
        "test_dataset = test_dataset.batch(batch_size)\n",
        "test_dataset = test_dataset.map(lambda q1,q2: ((q1,q2),1))\n",
        "test_dataset = test_dataset.prefetch(2)\n",
        "\n"
      ],
      "metadata": {
        "id": "iQnviZvmjFBv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "089b8d7f-b906-45d2-8d82-68d93fafb35b"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:3326: DtypeWarning: Columns (0) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_predict = siamese_model.predict(test_dataset,steps=test_data.shape[0]//batch_size + 1,verbose = 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6aeqjkrXvisS",
        "outputId": "127d32ca-402d-41fe-afda-79962b7c801b"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1146/1146 [==============================] - 1384s 1s/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data['is_duplicate'] = y_test_predict[:test_data.shape[0]]"
      ],
      "metadata": {
        "id": "_4fIm93Is74z"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission = test_data[['test_id','is_duplicate']].copy()\n",
        "submission.to_csv('/content/drive/MyDrive/Machine_Learning/NLP/Text Similarity/quora-questions/submission_baseline_1.csv',index = False)\n"
      ],
      "metadata": {
        "id": "5qzKiJ1MtAI6"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Further improvements could be brought by:-\n",
        "1.   Feature engineering like number of common words, characters in question pairs, etc.\n",
        "2.   Don't stem the words\n",
        "3.   Use glove embeddings instead of training new embeddings\n",
        "4.   Experiment with the d_model\n",
        "5.   Using BERT models or more complex models"
      ],
      "metadata": {
        "id": "ZGJA2pyFYpup"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O-iUYxt1YpWj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}